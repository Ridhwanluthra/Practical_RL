{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.array([[1./n_actions for _ in range(n_actions)] for _ in range(n_states)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray, np.matrix)\n",
    "assert np.allclose(policy, 1./n_actions)\n",
    "assert np.allclose(np.sum(policy, axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(policy, t_max=10**4):\n",
    "    \"\"\"\n",
    "    Play game until end or for t_max ticks.\n",
    "    :param policy: an array of shape [n_states,n_actions] with action probabilities\n",
    "    :returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0.\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        a = np.random.choice(n_actions, p=policy[s])\n",
    "        \n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # Record state, action and add up reward to states,actions and total_reward accordingly.\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r = generate_session(policy)\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) in [float, np.float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5c41d0b908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the initial reward distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
    "\n",
    "plt.hist(sample_rewards, bins=20)\n",
    "plt.vlines([np.percentile(sample_rewards, 50)], [0], [\n",
    "           100], label=\"50'th percentile\", color='green')\n",
    "plt.vlines([np.percentile(sample_rewards, 90)], [0], [\n",
    "           100], label=\"90'th percentile\", color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy method steps (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i][t]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you're confused, see examples below. Please don't assume that states are integers (they'll get different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    \n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "\n",
    "    for i, reward in enumerate(rewards_batch):\n",
    "        if reward >= reward_threshold:\n",
    "            elite_states.extend(states_batch[i])\n",
    "            elite_actions.extend(actions_batch[i])\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],  # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1]  # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],  # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3]  # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_40 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]),\\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]),\\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given old policy and a list of elite states/actions from select_elites,\n",
    "    return new updated policy where each action probability is proportional to\n",
    "\n",
    "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
    "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions])\n",
    "#     unique, counts = np.unique(elite_states, return_counts=True)\n",
    "#     print(unique, counts)\n",
    "    \n",
    "    for i, each_elite_state in enumerate(elite_states):\n",
    "        new_policy[each_elite_state][elite_actions[i]] += 1\n",
    "#         print(new_policy[each_elite_state])\n",
    "    \n",
    "    for i, each_state in enumerate(new_policy):\n",
    "        m = sum(each_state)\n",
    "        if m == 0:\n",
    "            new_policy[i] = np.fromiter((1/n_actions for _ in each_state), float)\n",
    "        else:\n",
    "            new_policy[i] = np.fromiter((x/m  for x in each_state), float)\n",
    "\n",
    "#     <Your code here: update probabilities for actions given elite states & actions >\n",
    "    \n",
    "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elite_states, elite_actions = ([1, 2, 3, 4, 2, 0, 2, 3, 1], [\n",
    "                               0, 2, 4, 3, 2, 0, 1, 3, 3])\n",
    "# elite_states, elite_actions = ([1, 2, 3, 4, 2, 1, 2, 3, 1], [\n",
    "#                                0, 2, 4, 3, 2, 0, 1, 3, 3])\n",
    "\n",
    "\n",
    "new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(\n",
    "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(\n",
    "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(\n",
    "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def show_progress(rewards_batch, log, reward_range=[-990, +10], show=True):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "    \n",
    "    if show:\n",
    "        clear_output(True)\n",
    "        print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "        plt.figure(figsize=[8, 4])\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "        plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(rewards_batch, range=reward_range)\n",
    "        plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "                   [0], [100], label=\"percentile\", color='red')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -28.240, threshold=8.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2b2920633c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     def generate_session(policy, t_max=10**4):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     %time sessions = [ < generate a list of n_sessions new sessions > ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2b2920633c8c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     def generate_session(policy, t_max=10**4):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     %time sessions = [ < generate a list of n_sessions new sessions > ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d8c234194d96>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(policy, t_max)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \"\"\"\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 1000  # sample this many sessions\n",
    "percentile = 50  # take this percent of session with highest rewards\n",
    "learning_rate = 0.5  # add this thing to all counts for stability\n",
    "\n",
    "log = []\n",
    "# reset policy just in case\n",
    "policy = np.ones([n_states, n_actions])/n_actions\n",
    "\n",
    "for i in range(1000):\n",
    "#     def generate_session(policy, t_max=10**4):\n",
    "#     %time sessions = [ < generate a list of n_sessions new sessions > ]\n",
    "    sessions = [ generate_session(policy) for _ in range(n_sessions) ]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "    policy = learning_rate*new_policy + (1-learning_rate)*policy\n",
    "    \n",
    "#     if i%50 == 0:\n",
    "#         learning_rate = 0.0001\n",
    "#     if np.mean(rewards_batch) > 0:\n",
    "#         learning_rate = 0.01\n",
    "\n",
    "    # display results on chart\n",
    "    if i%20 == 0:\n",
    "        show_progress(rewards_batch, log, show=True)\n",
    "    else:\n",
    "        show_progress(rewards_batch, log, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging deeper: approximate crossentropy with neural nets\n",
    "\n",
    "![img](https://casd35.wikispaces.com/file/view/digging_deeper_final.jpg/359658499/503x260/digging_deeper_final.jpg)\n",
    "\n",
    "In this section we will train a neural network policy for continuous state space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box2d\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/7b/ddb96fea1fa5b24f8929714ef483f64c33e9649e7aae066e5f5023ea426a/Box2D-2.3.2.tar.gz (427kB)\n",
      "\u001b[K    100% |████████████████████████████████| 430kB 19.4MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: box2d\n",
      "  Running setup.py install for box2d ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed box2d-2.3.2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE+tJREFUeJzt3X+MpdV93/H3pywGx3a9YG/RsrsU3GxioaheYItBcSKC5QQo6hIptbCqGrmok0pYspWoDaRSbdTmj0iJaa1UqJvgeF25YIrtsFq5dTCmSvuHwYu9Xu+yJl7HWOxmYWn4YVOrNIu//eOegZvZH3Pnx52598z7JV3N85znufc5Z+bO554595y5qSokSf35W6tdAUnSeBjwktQpA16SOmXAS1KnDHhJ6pQBL0mdGlvAJ7kuyZNJDie5fVzXkSSdWsYxDz7JWcCfA+8DjgBfBz5QVU8s+8UkSac0rh78lcDhqvqLqvp/wH3AjjFdS5J0CuvG9LibgKeH9o8A7z7dyUlcTqtl9da3buSnzt7Aj//6OV566dhr+8vhVI85WyYtp6rKUu4/roCfV5IZYGa1rq9+3Xjjx7jiwsFT6/G/3MmePXfyC78w81rZUp3qMWfLpEkyriGao8CWof3Nrew1VbWzqrZX1fYx1UFr3ON/uXOsj79nz52vXeOKC2e48caPjfV60kKNK+C/DmxNckmSNwA3A7vHdC3pNcO9d2BFetXjfiGRFmssAV9VJ4APA18GDgH3V9XBcVxLOpWVGjIZvoa9eE2asY3BV9WXgC+N6/Glueb23oft2XMn3Die684+9nKN8UvLZdXeZJXG5XS995Xo0V9x4QzcuDLXkuZjwKsrqzUePvwXguGuSWHAqxuTEKyTUAdp1lj+VcGCK+FCJ0k6yVIXOvnfJCWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSp5b0/+CTPAX8CHgVOFFV25OcD3wOuBh4Cnh/Vb2wtGpKkhZqOXrwv1RV26pqe9u/HXi4qrYCD7d9SdIKG8cQzQ5gV9veBdw0hmtIkuax1IAv4E+TPJ5k9iPlL6iqY237GeCCJV5DkrQIS/1M1vdU1dEkfwd4KMl3hg9WVZ3u4/jaC8LMqY5JkpZu2T6TNcnHgZeBfw5cU1XHkmwE/kdV/ew89/UzWSVpjlX7TNYkb0ryltlt4JeBA8Bu4JZ22i3Ag0upoCRpcRbdg0/yDuCLbXcd8F+q6neSvA24H7gI+AGDaZLPz/NY9uAlaY6l9uCXbYhmSZUw4CXpJKs2RCNJmmwGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekTs0b8Ek+leR4kgNDZecneSjJd9vX81p5knwyyeEk+5NcPs7KS5JOb5Qe/KeB6+aU3Q48XFVbgYfbPsD1wNZ2mwHuXp5qSpIWat6Ar6o/A56fU7wD2NW2dwE3DZV/pga+BqxPsnG5KitJGt1ix+AvqKpjbfsZ4IK2vQl4eui8I63sJElmkuxNsneRdZAkncG6pT5AVVWSWsT9dgI7ARZzf0nSmS22B//s7NBL+3q8lR8Ftgydt7mVSZJW2GIDfjdwS9u+BXhwqPyDbTbNVcBLQ0M5kqQVlKozj44kuRe4Bng78CzwMeBPgPuBi4AfAO+vqueTBPgDBrNufgx8qKrmHWN3iEaSTlZVWcr95w34lWDAS9LJlhrwrmSVpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktSpeQM+yaeSHE9yYKjs40mOJtnXbjcMHbsjyeEkTyb5lXFVXJJ0ZqN86PYvAi8Dn6mqn2tlHwderqrfm3PupcC9wJXAhcBXgJ+pqlfnuYafySpJc4z9M1mr6s+A50d8vB3AfVX1SlV9HzjMIOwlSStsKWPwH06yvw3hnNfKNgFPD51zpJWdJMlMkr1J9i6hDpKk01hswN8N/D1gG3AM+P2FPkBV7ayq7VW1fZF1kCSdwaICvqqerapXq+onwB/y+jDMUWDL0KmbW5kkaYUtKuCTbBza/VVgdobNbuDmJOckuQTYCjy2tCpKkhZj3XwnJLkXuAZ4e5IjwMeAa5JsAwp4Cvh1gKo6mOR+4AngBHDbfDNoJEnjMe80yRWphNMkJekkY58mKUmaTga8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdWregE+yJckjSZ5IcjDJR1r5+UkeSvLd9vW8Vp4kn0xyOMn+JJePuxGSpJON0oM/AfxmVV0KXAXcluRS4Hbg4araCjzc9gGuB7a22wxw97LXWpI0r3kDvqqOVdU32vaPgEPAJmAHsKudtgu4qW3vAD5TA18D1ifZuOw1lySd0YLG4JNcDFwGPApcUFXH2qFngAva9ibg6aG7HWllcx9rJsneJHsXWGdJ0ghGDvgkbwY+D3y0qn44fKyqCqiFXLiqdlbV9qravpD7SZJGM1LAJzmbQbh/tqq+0IqfnR16aV+Pt/KjwJahu29uZZKkFTTKLJoA9wCHquoTQ4d2A7e07VuAB4fKP9hm01wFvDQ0lCNJWiEZjK6c4YTkPcD/BL4N/KQV/zaDcfj7gYuAHwDvr6rn2wvCHwDXAT8GPlRVZxxnT7Kg4R1JWguqKku5/7wBvxIMeEk62VID3pWsktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoAHqopJWA8gSctp3WpXYLUNB/vw9mBBriRNrzUb8PP12GePG/SSptWaDPiFDMfYq5c0rdZUwC91nN2wlzRNfJN1kXxTVtKkWxM9+HGFsT16SZOs+x78SvW0nWopadJ024NfrbB19o2kSdFlwE9CT9rhG0mrrbshmkkI97kcvpG0Gkb50O0tSR5J8kSSg0k+0so/nuRokn3tdsPQfe5IcjjJk0l+ZZwNGDbpIWrQS1pJo3zo9kZgY1V9I8lbgMeBm4D3Ay9X1e/NOf9S4F7gSuBC4CvAz1TVq2e4xpJSb1pD06EbSWcy9s9krapjVfWNtv0j4BCw6Qx32QHcV1WvVNX3gcMMwn4spjXc4fUe/TS3QdLkWtAYfJKLgcuAR1vRh5PsT/KpJOe1sk3A00N3O8KZXxAWradgNOwH34O9e1e7FqvP74GWy8izaJK8Gfg88NGq+mGSu4F/C1T7+vvAP1vA480AMwur7ut6DsK1PtXyVAG3ffvK12M1nS7k19r3QUszUsAnOZtBuH+2qr4AUFXPDh3/Q2BP2z0KbBm6++ZW9jdU1U5gZ7v/yGndc7DPtdaDfpiBN+CLnxZilFk0Ae4BDlXVJ4bKNw6d9qvAgba9G7g5yTlJLgG2Ao8tR2XXUrgPW+tDN5IWZ5Qe/M8D/xT4dpJ9rey3gQ8k2cZgiOYp4NcBqupgkvuBJ4ATwG1nmkEzKgNubffo7aUO+H3QQsw7TXJFKjHPEM0k1HFS9RT2VcXjj2fNh9jevQa5BpY6TXKiA34S6jZNpj3sq2rq2yAtp7HPg18thvvCOVYvadjE/bMxA2rp/EdnkmCCe/BaHr5gSmvXxPTgDaLxsUcvrU0T0YO/4oorVrsKa4bj9NLaMTE9eK0se/VS/wx4GfZSpyZiiEaTwyEcqR8GvE7JkJemn0M0Oi2HbqTpZg9eI3HoRpo+9uC1IPbqpelhD16LZq9emmwGvJbMoJcmkwGvZWPQS5PFMXgtu7X8yVNaHuPsKKz283LUtm1fhk99MeA1Nga9Fmol/gJcS39ljvKh2+cmeSzJt5IcTHJnK78kyaNJDif5XJI3tPJz2v7hdvzi8TZBk2526GYt/WJpYXx+jMcoY/CvANdW1buAbcB1Sa4Cfhe4q6p+GngBuLWdfyvwQiu/q50nAf4i62/y+TBe8wZ8Dbzcds9utwKuBR5o5buAm9r2jrZPO/7e+De65rBXv7b5s18ZI82iSXJWkn3AceAh4HvAi1V1op1yBNjUtjcBTwO04y8Bb1vOSqsvs7/s9gP6Z7CvrJHeZK2qV4FtSdYDXwTeudQLJ5kBZgAuuuiipT6cOuAv/ut6fLHz57vyFjQPvqpeBB4BrgbWJ5l9gdgMHG3bR4EtAO34W4G/OsVj7ayq7VW1fcOGDYusvtSnXoawemnHtBplFs2G1nMnyRuB9wGHGAT9r7XTbgEebNu72z7t+FfLn660aNMaktNW3x6NMkSzEdiV5CwGLwj3V9WeJE8A9yX5d8A3gXva+fcA/znJYeB54OYx1Ftak+aG5iQO5Rjsk2PegK+q/cBlpyj/C+DKU5T/X+AfL0vtJJ3RpCwmM9QnkytZpQ6sVs/eYJ9s/rMxqUMGr8AevNStcX44iy8g08GAl9aA5Qh7Q336GPDSGrPQsDfYp5cBL61h8705a7hPNwNe0msM9L44i0aSOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SerUKB+6fW6Sx5J8K8nBJHe28k8n+X6Sfe22rZUnySeTHE6yP8nl426EJOlko/yzsVeAa6vq5SRnA/8ryX9rx/5lVT0w5/zrga3t9m7g7vZVkrSC5u3B18DLbffsdjvTv5zbAXym3e9rwPokG5deVUnSQow0Bp/krCT7gOPAQ1X1aDv0O20Y5q4k57SyTcDTQ3c/0sokSStopICvqlerahuwGbgyyc8BdwDvBP4BcD7wWwu5cJKZJHuT7H3uuecWWG1J0nwWNIumql4EHgGuq6pjbRjmFeCPgSvbaUeBLUN329zK5j7WzqraXlXbN2zYsLjaS5JOa5RZNBuSrG/bbwTeB3xndlw9g8/4ugk40O6yG/hgm01zFfBSVR0bS+0lSac1yiyajcCuJGcxeEG4v6r2JPlqkg1AgH3Av2jnfwm4ATgM/Bj40PJXW5I0n3kDvqr2A5edovza05xfwG1Lr5okaSlcySpJnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1auSAT3JWkm8m2dP2L0nyaJLDST6X5A2t/Jy2f7gdv3g8VZcknclCevAfAQ4N7f8ucFdV/TTwAnBrK78VeKGV39XOkyStsJECPslm4B8Cf9T2A1wLPNBO2QXc1LZ3tH3a8fe28yVJK2jdiOf9e+BfAW9p+28DXqyqE23/CLCpbW8CngaoqhNJXmrn/+/hB0wyA8y03VeSHFhUCybf25nT9k702i7ot222a7r83SQzVbVzsQ8wb8AnuRE4XlWPJ7lmsReaq1V6Z7vG3qravlyPPUl6bVuv7YJ+22a7pk+SvbScXIxRevA/D/yjJDcA5wJ/G/gPwPok61ovfjNwtJ1/FNgCHEmyDngr8FeLraAkaXHmHYOvqjuqanNVXQzcDHy1qv4J8Ajwa+20W4AH2/butk87/tWqqmWttSRpXkuZB/9bwG8kOcxgjP2eVn4P8LZW/hvA7SM81qL/BJkCvbat13ZBv22zXdNnSW2LnWtJ6pMrWSWpU6se8EmuS/JkW/k6ynDOREnyqSTHh6d5Jjk/yUNJvtu+ntfKk+STra37k1y+ejU/syRbkjyS5IkkB5N8pJVPdduSnJvksSTfau26s5V3sTK71xXnSZ5K8u0k+9rMkql/LgIkWZ/kgSTfSXIoydXL2a5VDfgkZwH/EbgeuBT4QJJLV7NOi/Bp4Lo5ZbcDD1fVVuBhXn8f4npga7vNAHevUB0X4wTwm1V1KXAVcFv72Ux7214Brq2qdwHbgOuSXEU/K7N7XnH+S1W1bWhK5LQ/F2EwI/G/V9U7gXcx+NktX7uqatVuwNXAl4f27wDuWM06LbIdFwMHhvafBDa27Y3Ak237PwEfONV5k35jMEvqfT21Dfgp4BvAuxkslFnXyl97XgJfBq5u2+vaeVntup+mPZtbIFwL7AHSQ7taHZ8C3j6nbKqfiwymkH9/7vd9Odu12kM0r616bYZXxE6zC6rqWNt+BrigbU9le9uf75cBj9JB29owxj7gOPAQ8D1GXJkNzK7MnkSzK85/0vZHXnHOZLcLoIA/TfJ4WwUP0/9cvAR4DvjjNqz2R0nexDK2a7UDvns1eKmd2qlKSd4MfB74aFX9cPjYtLatql6tqm0MerxXAu9c5SotWYZWnK92XcbkPVV1OYNhituS/OLwwSl9Lq4DLgfurqrLgP/DnGnlS23Xagf87KrXWcMrYqfZs0k2ArSvx1v5VLU3ydkMwv2zVfWFVtxF2wCq6kUGC/aupq3MbodOtTKbCV+ZPbvi/CngPgbDNK+tOG/nTGO7AKiqo+3rceCLDF6Yp/25eAQ4UlWPtv0HGAT+srVrtQP+68DW9k7/GxislN29ynVaDsOreeeu8v1gezf8KuCloT/FJkqSMFi0dqiqPjF0aKrblmRDkvVt+40M3lc4xJSvzK6OV5wneVOSt8xuA78MHGDKn4tV9QzwdJKfbUXvBZ5gOds1AW803AD8OYNx0H+92vVZRP3vBY4Bf83gFflWBmOZDwPfBb4CnN/ODYNZQ98Dvg1sX+36n6Fd72Hwp+F+YF+73TDtbQP+PvDN1q4DwL9p5e8AHgMOA/8VOKeVn9v2D7fj71jtNozQxmuAPb20q7XhW+12cDYnpv252Oq6Ddjbno9/Apy3nO1yJaskdWq1h2gkSWNiwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1Kn/DyU2Us5jMe4RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "# !pip install box2d\n",
    "env = gym.make(\"LunarLander-v2\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ridhwan/openaigym/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create agent\n",
    "# !pip install sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20, 20),\n",
    "                      activation='tanh',\n",
    "                      warm_start=True,  # keep progress between .fit(...) calls\n",
    "                      max_iter=1  # make only 1 iteration on each .fit(...)\n",
    "                      )\n",
    "# initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000):\n",
    "\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        a = np.random.choice(n_actions, p=probs)\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 41.086, threshold=69.200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IsLocked() == false",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_destroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContactDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener_keepref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_destroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontactListener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_clean_particles\u001b[0;34m(self, all)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clean_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDestroyBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: IsLocked() == false"
     ]
    }
   ],
   "source": [
    "# !pip install joblib\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "#     %time sessions = Parallel(n_jobs=4)(delayed(generate_session) for _ in range(n_sessions))\n",
    "    %time sessions = [ generate_session() for _ in range(n_sessions) ]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    \n",
    "    agent.fit(elite_states, elite_actions)\n",
    "\n",
    "#     <fit agent to predict elite_actions(y) from elite_states(X) >\n",
    "#     if i % 10 == 0:\n",
    "#         show_progress(rewards_batch, log, reward_range=[0, np.max(rewards_batch)])\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        show_progress(rewards_batch, log, show=True)\n",
    "    else:\n",
    "        show_progress(rewards_batch, log, show=False)\n",
    "\n",
    "#     if np.mean(rewards_batch) > 190:\n",
    "#         print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a3e86fdb0f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# upload to gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a3e86fdb0f97>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# upload to gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a9dcc5f72f9f>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnew_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# record sessions like you did before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openaigym/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplyLinearImpulse\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "# upload to gym\n",
    "# gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.1.18650.video000027.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you change different percentile and different n_samples.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to upload the result and get to something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "  * For any environment, upload it to gym and post url in your anytask form.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [mountaincar](https://gym.openai.com/envs/MountainCar-v0), [lunarlander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "* __Please upload the results to openai gym and send links to all submissions in the e-mail__\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaigym",
   "language": "python",
   "name": "openaigym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
